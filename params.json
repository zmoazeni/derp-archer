{"note":"Don't delete this file! It's used internally to help with page regeneration.","google":"","body":"# A basic prototype of a rewrite of DelayedJob that includes these concepts:\r\n\r\nBasically it keeps the same essence of what I think makes DJ great: \"small and simple to get started and run\". It also rips out a large swath of dependencies that makes maintenance tougher. It retains a Resque-like API to let the codebase upgrade to another Qu backend/Resque/Sidekiq when their app needs more power.\r\n\r\n* Ripping out AR/Mongo/etc and using [leveldb](http://code.google.com/p/leveldb/) as the sole backend\r\n* Reusing [Qu's](https://github.com/bkeepers/qu) existing architecture\r\n  (though I'm already starting to depart from his initial design)\r\n* 1 fork per job with a maximum number of workers (inefficient, but\r\n  hey upgrade to something else if you need more) - won't allow\r\n  spreading workers among machines.\r\n* Using sinatra/thin to enqueue jobs\r\n\r\n# To Run with a sample worker\r\n\r\n    bundle\r\n    bundle exec ruby -I. ./playing/test_worker.rb\r\n\r\n# How it works\r\n\r\nThe architecture is laid out like this:\r\n\r\n  - Only one process is started by the user.\r\n    - From Qu's perspective, this is 1 \"worker\" (see below)\r\n  - The library wraps Qu overriding a Qu::Worker, and the user uses\r\n    DelayedJob.configure\r\n  - The library implements a Qu backend that acts as backend interface\r\n    to 3 separate leveldb databases (queued, running, failed)\r\n    - These are lightweight dbs that are treated more like\r\n      collections.\r\n    - If you haven't used leveldb before, it's essentially a\r\n      persistent hash with sorted keys\r\n    - Only one process can open a leveldb database at once, which is\r\n      influencing some of software design\r\n  - The library mostly follow's Qu's conventions however the worker\r\n    isn't actually doing the work. The worker will fork a process per\r\n    job (with a maximum number of children).\r\n      - The maximum children lets us keep the memory footprint bounded\r\n      - Forking 1 process per job (a la resque) is inefficient however\r\n        it's efficient enough for DJ\r\n      - Forking per job also avoids memory leaks that may arise from\r\n        the app. The child will take any memory hits and then dies/releases memory at\r\n        the end of the job.\r\n      - (Potential feature: adding a sinatra/server route that lets\r\n        you change the maximum number of children at runtime)\r\n  - The worker will also start a sinatra app using thin. This is actually how jobs are enqueued\r\n    - This could be a fully fledged JSON API which allows a user to inspect the queue, running jobs, failed jobs, etc.\r\n  - Benefits of depending on Qu:\r\n    - Simple codebase. We don't need to maintain a full front-end\r\n    - Qu/Resque/Sidekiq use a very similiar API. So someone starting\r\n       with DelayedJob wouldn't have to change much to swap out a\r\n       different architecture\r\n    - We can reuse Qu plugins such as Error handlers\r\n  - Benefits of depending on LevelDB\r\n    - No longer depend on MySQL or Mongo for managing the queue (I\r\n       should benchmark leveldb, but my intuition is that it's much faster)\r\n    - It separates and simplifies our storage. We no longer need to\r\n      provide a mysql migration or maintain our\r\n      connection with ActiveRecord or MongoMapper\r\n  - Qu and LevelDB lets people can use DelayedJob on non-Rails projects\r\n  - Downsides: \r\n    - The current front-end for delaying jobs is slick\r\n    - We can't split workers among multiple machines (though the worker can be started elsewhere). This may become a line in the\r\n     sand to prompt people to upgrade to a different background processor\r\n\r\n# What is with the repo name?\r\n\r\nI just chose a name that github provided :)\r\n","name":"Derp-archer","tagline":"Playing around with bg processing"}